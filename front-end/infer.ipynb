{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firtst\n",
      "second\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler  # If used during training\n",
    "from ModelTrainer import ModelTrainer  # If available\n",
    "from params import MODELS_DIR\n",
    "\n",
    "\n",
    "# Define the directory where models are saved\n",
    "MODELS_DIR = \"/home/peiman/openwhisk/front-end/models/remote\"\n",
    "input_size_model_path = os.path.join(MODELS_DIR, 'model_RandomForest_Function Input.pkl')  # Example model for Input Size\n",
    "cpu_model_path = os.path.join(MODELS_DIR, 'model_RandomForest_Max CPU Usage.pkl')  # Example model for CPU\n",
    "mem_model_path = os.path.join(MODELS_DIR, 'model_RandomForest_Max Memory Usage.pkl')  # Example model for Memory\n",
    "\n",
    "\n",
    "cpu_model = joblib.load(cpu_model_path)\n",
    "mem_model = joblib.load(mem_model_path)\n",
    "size_model = joblib.load(input_size_model_path)\n",
    "\n",
    "# Load new data\n",
    "data_path = '/home/peiman/openwhisk/front-end/logs/remote/new_data.csv'\n",
    "new_data = pd.read_csv(data_path)\n",
    "\n",
    "features = ['DAG Input Size', 'Function Name']\n",
    "target = 'Function Input'\n",
    "\n",
    "X_new = ModelTrainer(None).prepare_inference_data(new_data, features)\n",
    "\n",
    "new_data['Predicted Input Size'] = size_model.predict(X_new)\n",
    "X_new['Predicted Input Size'] = new_data['Predicted Input Size'].values\n",
    "    \n",
    "\n",
    "# Assuming 'ModelTrainer' or similar utility for data preparation is available\n",
    "# Prepare data (ensure the feature names and model input match training setup)\n",
    "features = ['Function Name', 'Predicted Input Size']  # Example features used for training\n",
    "target = 'Max CPU Usage'  # Example target used for training\n",
    "X_new = ModelTrainer(None).prepare_inference_data(new_data, features)\n",
    "\n",
    "# X_new = new_data[features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Unique DAG ID  DAG Input Content  DAG Input Size  \\\n",
      "0  AS-69f6ee95-7e43-423c-aa76-38200707cada                 50           10200   \n",
      "1  AS-69f6ee95-7e43-423c-aa76-38200707cada                 50           10200   \n",
      "2  AS-69f6ee95-7e43-423c-aa76-38200707cada                 50           10200   \n",
      "3  AS-69f6ee95-7e43-423c-aa76-38200707cada                 50           10200   \n",
      "4  AS-69f6ee95-7e43-423c-aa76-38200707cada                 50           10200   \n",
      "\n",
      "  Function Name  Function Input  Duration  Parallel Duration  \\\n",
      "0         wait1           10200      1229                NaN   \n",
      "1          AES1           10200      6306            19452.0   \n",
      "2          AES2           40800     13156            19452.0   \n",
      "3          AES3           91800     19452            19452.0   \n",
      "4         Stats           10200       234                NaN   \n",
      "\n",
      "   Memory_Allocated  CPU_Allocated  Max Memory Usage  Max CPU Usage  \\\n",
      "0               128              1          9.707520       0.011877   \n",
      "1               256              8         21.561344       0.652813   \n",
      "2               256              8         27.881472       3.682386   \n",
      "3               256              8         32.485376       3.381299   \n",
      "4               128              1          9.920512       0.006234   \n",
      "\n",
      "   Avg CPU Usage     Start Time       End Time  Timeout Status  \\\n",
      "0       0.005610  1712869110671  1712869111900           False   \n",
      "1       0.624697  1712869113282  1712869119588           False   \n",
      "2       1.264223  1712869113514  1712869126670           False   \n",
      "3       1.867068  1712869113286  1712869132738           False   \n",
      "4       0.006234  1712869133206  1712869133440           False   \n",
      "\n",
      "                                     Input File  Predicted Input Size  \\\n",
      "0  ./profiling/aes_inputs_100content/run83.json               10194.0   \n",
      "1  ./profiling/aes_inputs_100content/run83.json               10195.0   \n",
      "2  ./profiling/aes_inputs_100content/run83.json               40768.0   \n",
      "3  ./profiling/aes_inputs_100content/run83.json               91602.0   \n",
      "4  ./profiling/aes_inputs_100content/run83.json               10194.0   \n",
      "\n",
      "   Predicted Max CPU Usage  Predicted Max Memory Usage  \n",
      "0                 0.013183                    9.874924  \n",
      "1                 0.658172                   23.484334  \n",
      "2                 1.309129                   27.650253  \n",
      "3                 1.988544                   33.783480  \n",
      "4                 0.004433                   11.047854  \n"
     ]
    }
   ],
   "source": [
    "#change column name from  Predicted Input Size to Function Input\n",
    "X_new = X_new.rename(columns = {'Predicted Input Size':'Function Input'})\n",
    "new_data['Predicted Max CPU Usage'] = cpu_model.predict(X_new)\n",
    "new_data['Predicted Max Memory Usage'] = mem_model.predict(X_new)\n",
    "new_data.to_csv('./updated_new_data.csv', index=False)  # Save to CSV\n",
    "print(new_data.head())  # Display the first few rows of the updated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'ModelTrainer' or similar utility for data preparation is available\n",
    "# Prepare data (ensure the feature names and model input match training setup)\n",
    "features = ['Function Name', 'Predicted Input Size']  # Example features used for training\n",
    "target = 'Max CPU Usage'  # Example target used for training\n",
    "X_new = ModelTrainer(None).prepare_inference_data(new_data, features)\n",
    "\n",
    "# X_new = new_data[features]\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "new_data['Predicted Max CPU Usage'] = cpu_model.predict(X_new)\n",
    "new_data['Predicted Max Memory Usage'] = mem_model.predict(X_new)\n",
    "\n",
    "# Save or display the updated DataFrame\n",
    "new_data.to_csv('./updated_new_data.csv', index=False)  # Save to CSV\n",
    "print(new_data.head())  # Display the first few rows of the updated DataFrame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimbus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
