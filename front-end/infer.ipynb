{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler  # If used during training\n",
    "from ModelTrainer import ModelTrainer  # If available\n",
    "from params import MODELS_DIR\n",
    "\n",
    "\n",
    "# Define the directory where models are saved\n",
    "input_size_model_path = os.path.join(MODELS_DIR, 'model_RandomForest_Function Input.pkl')  # Example model for Input Size\n",
    "cpu_model_path = os.path.join(MODELS_DIR, 'model_RandomForest_Max CPU Usage.pkl')  # Example model for CPU\n",
    "mem_model_path = os.path.join(MODELS_DIR, 'model_RandomForest_Max Memory Usage.pkl')  # Example model for Memory\n",
    "\n",
    "\n",
    "cpu_model = joblib.load(cpu_model_path)\n",
    "mem_model = joblib.load(mem_model_path)\n",
    "size_model = joblib.load(input_size_model_path)\n",
    "\n",
    "# Load new data\n",
    "data_path = './mytest.csv'\n",
    "new_data = pd.read_csv(data_path)\n",
    "\n",
    "features = ['DAG Input Size', 'Function Name']\n",
    "target = 'Function Input'\n",
    "\n",
    "X_new = ModelTrainer(None).prepare_inference_data(new_data, features)\n",
    "\n",
    "new_data['Predicted Input Size'] = size_model.predict(X_new)\n",
    "X_new['Predicted Input Size'] = new_data['Predicted Input Size'].values\n",
    "    \n",
    "\n",
    "# Assuming 'ModelTrainer' or similar utility for data preparation is available\n",
    "# Prepare data (ensure the feature names and model input match training setup)\n",
    "features = ['Function Name', 'Predicted Input Size']  # Example features used for training\n",
    "target = 'Max CPU Usage'  # Example target used for training\n",
    "X_new = ModelTrainer(None).prepare_inference_data(new_data, features)\n",
    "\n",
    "# X_new = new_data[features]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Unique DAG ID  DAG Input Content  DAG Input Size  \\\n",
      "0  AS-11e89baf-979f-4b15-9337-485987d59503                 50           10200   \n",
      "1  AS-9f122354-8cb0-419e-9bd1-e6520454e430                 50            4200   \n",
      "2  AS-49e2b177-2137-4541-a2d6-7629af7284bd                 50            6300   \n",
      "3  AS-49e2b177-2137-4541-a2d6-7629af7284bd                 50            6300   \n",
      "4  AS-2ec208de-f336-4341-999b-3e7f0ea1522d                 50            2400   \n",
      "\n",
      "  Function Name  Function Input  Duration  Parallel Duration  \\\n",
      "0          AES1           10200      4137            12029.0   \n",
      "1          AES3           37800      5064             5064.0   \n",
      "2         wait1            6300      1005                NaN   \n",
      "3          AES1            6300      2439             7600.0   \n",
      "4         Stats            2400        25                NaN   \n",
      "\n",
      "   Memory_Allocated  CPU_Allocated  Max Memory Usage  Max CPU Usage  \\\n",
      "0               256              8         21.536768       0.669724   \n",
      "1               256              8         33.103872       1.961415   \n",
      "2               128              1          9.646080       0.014524   \n",
      "3               256              8         21.938176       0.661051   \n",
      "4               128              1         10.489856       0.003552   \n",
      "\n",
      "   Avg CPU Usage     Start Time       End Time  Timeout Status  \\\n",
      "0       0.625935  1712867476463  1712867480600           False   \n",
      "1       1.791766  1712867498855  1712867503919           False   \n",
      "2       0.005738  1712867511841  1712867512846           False   \n",
      "3       0.620295  1712867512897  1712867515336           False   \n",
      "4       0.003552  1712867536008  1712867536033           False   \n",
      "\n",
      "                          Input File  Predicted Input Size  \\\n",
      "0  ./profiling/aes_inputs/run83.json               10180.0   \n",
      "1  ./profiling/aes_inputs/run23.json               37350.0   \n",
      "2  ./profiling/aes_inputs/run44.json                6284.0   \n",
      "3  ./profiling/aes_inputs/run44.json                6277.0   \n",
      "4   ./profiling/aes_inputs/run5.json                2405.0   \n",
      "\n",
      "   Predicted Max CPU Usage  Predicted Max Memory Usage  \n",
      "0                 0.658350                   23.545897  \n",
      "1                 1.978480                   35.927941  \n",
      "2                 0.015836                   10.895606  \n",
      "3                 0.653236                   24.062321  \n",
      "4                 0.004084                   12.661391  \n"
     ]
    }
   ],
   "source": [
    "#change column name from  Predicted Input Size to Function Input\n",
    "X_new = X_new.rename(columns = {'Predicted Input Size':'Function Input'})\n",
    "new_data['Predicted Max CPU Usage'] = cpu_model.predict(X_new)\n",
    "new_data['Predicted Max Memory Usage'] = mem_model.predict(X_new)\n",
    "new_data.to_csv('./updated_new_data.csv', index=False)  # Save to CSV\n",
    "print(new_data.head())  # Display the first few rows of the updated DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Predicted Input Size\nFeature names seen at fit time, yet now missing:\n- Function Input\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m X_new \u001b[38;5;241m=\u001b[39m ModelTrainer(\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mprepare_inference_data(new_data, features)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# X_new = new_data[features]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Max CPU Usage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcpu_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Max Memory Usage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m mem_model\u001b[38;5;241m.\u001b[39mpredict(X_new)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save or display the updated DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nimbus/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:1064\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1062\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m-> 1064\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nimbus/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nimbus/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nimbus/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Predicted Input Size\nFeature names seen at fit time, yet now missing:\n- Function Input\n"
     ]
    }
   ],
   "source": [
    "# # Assuming 'ModelTrainer' or similar utility for data preparation is available\n",
    "# # Prepare data (ensure the feature names and model input match training setup)\n",
    "# features = ['Function Name', 'Predicted Input Size']  # Example features used for training\n",
    "# target = 'Max CPU Usage'  # Example target used for training\n",
    "# X_new = ModelTrainer(None).prepare_inference_data(new_data, features)\n",
    "\n",
    "# # X_new = new_data[features]\n",
    "\n",
    "\n",
    "# # Make predictions\n",
    "# new_data['Predicted Max CPU Usage'] = cpu_model.predict(X_new)\n",
    "# new_data['Predicted Max Memory Usage'] = mem_model.predict(X_new)\n",
    "\n",
    "# # Save or display the updated DataFrame\n",
    "# new_data.to_csv('./updated_new_data.csv', index=False)  # Save to CSV\n",
    "# print(new_data.head())  # Display the first few rows of the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1188118811881188"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ModelEvalNew import ensure_1d_array\n",
    "y_test = new_data['Max CPU Usage']\n",
    "y_pred = new_data['Predicted Max CPU Usage']\n",
    "cpu_err, cpu_err_list = ModelTrainer.calculate_cpu_usage_error_rate(ensure_1d_array(y_test), ensure_1d_array(y_pred))\n",
    "cpu_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ModelEvalNew import ensure_1d_array\n",
    "y_test = new_data['Max Memory Usage']\n",
    "y_pred = new_data['Predicted Max Memory Usage']\n",
    "mem_err, mem_err_list = ModelTrainer.calculate_memory_usage_error_rate(ensure_1d_array(y_test), ensure_1d_array(y_pred))\n",
    "mem_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['wait1', 'AES1', 'AES2', 'AES3', 'Stats']\n",
    "DAG_input_size = [5000, 5000, 5000, 5000, 5000] \n",
    "# Function_input = [0, 0, 0, 0, 0]\n",
    "dict = {'Function Name': names, 'DAG Input Size': DAG_input_size, 'Function Input': Function_input}\n",
    "request = pd.DataFrame(dict)\n",
    "\n",
    "features = ['DAG Input Size', 'Function Name']\n",
    "target = 'Function Input'\n",
    "\n",
    "\n",
    "X_new = ModelTrainer(None).prepare_inference_data(request, features)\n",
    "\n",
    "request['Predicted Input Size'] = size_model.predict(X_new)\n",
    "X_new['Predicted Input Size'] = request['Predicted Input Size'].values\n",
    "    \n",
    "\n",
    "# Assuming 'ModelTrainer' or similar utility for data preparation is available\n",
    "# Prepare data (ensure the feature names and model input match training setup)\n",
    "features = ['Function Name', 'Predicted Input Size']  # Example features used for training\n",
    "target = 'Max CPU Usage'  # Example target used for training\n",
    "X_new = ModelTrainer(None).prepare_inference_data(request, features)\n",
    "\n",
    "#change column name from  Predicted Input Size to Function Input\n",
    "X_new = X_new.rename(columns = {'Predicted Input Size':'Function Input'})\n",
    "request['Predicted Max CPU Usage'] = cpu_model.predict(X_new)\n",
    "request['Predicted Max Memory Usage'] = mem_model.predict(X_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function Name</th>\n",
       "      <th>DAG Input Size</th>\n",
       "      <th>Function Input</th>\n",
       "      <th>Predicted Input Size</th>\n",
       "      <th>Predicted Max CPU Usage</th>\n",
       "      <th>Predicted Max Memory Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wait1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>4996.0</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>10.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AES1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>0.655869</td>\n",
       "      <td>22.907126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AES2</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>19960.0</td>\n",
       "      <td>1.307078</td>\n",
       "      <td>28.286362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AES3</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>44649.0</td>\n",
       "      <td>1.971335</td>\n",
       "      <td>34.219090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stats</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>4996.0</td>\n",
       "      <td>0.004952</td>\n",
       "      <td>10.984899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Function Name  DAG Input Size  Function Input  Predicted Input Size  \\\n",
       "0         wait1            5000               0                4996.0   \n",
       "1          AES1            5000               0                4998.0   \n",
       "2          AES2            5000               0               19960.0   \n",
       "3          AES3            5000               0               44649.0   \n",
       "4         Stats            5000               0                4996.0   \n",
       "\n",
       "   Predicted Max CPU Usage  Predicted Max Memory Usage  \n",
       "0                 0.015254                   10.003743  \n",
       "1                 0.655869                   22.907126  \n",
       "2                 1.307078                   28.286362  \n",
       "3                 1.971335                   34.219090  \n",
       "4                 0.004952                   10.984899  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimbus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
