{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./logs/500run2.csv')\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to compute BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# List to store each row of the new dataset\n",
    "new_dataset_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    unique_dag_id = row['Unique DAG ID']\n",
    "    func_name = row['Function Name']\n",
    "    input_file_path = row['Input File']\n",
    "    \n",
    "    # Load the JSON content from the input file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Extract the specific part of the JSON relevant to the current function\n",
    "    if func_name in data['data']:\n",
    "        func_data = json.dumps(data['data'][func_name])\n",
    "        embedding = get_bert_embedding(func_data)\n",
    "        new_row = {\n",
    "            'Unique DAG ID': unique_dag_id,\n",
    "            'Function Name': func_name,\n",
    "            'BERT Embedding': embedding,\n",
    "            'Max CPU Usage': row['Max CPU Usage'],\n",
    "            'Max Memory Usage': row['Max Memory Usage']\n",
    "        }\n",
    "        new_dataset_rows.append(new_row)\n",
    "\n",
    "# Convert the list of new rows into a DataFrame\n",
    "final_df = pd.DataFrame(new_dataset_rows)\n",
    "\n",
    "# Display or save the final dataset\n",
    "# print(final_df.head())  # For display\n",
    "final_df.to_csv('functions_profiled_dataset_with_embeddings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AES1' 'AES2' 'AES3']\n"
     ]
    }
   ],
   "source": [
    "# show all exisiting values for the function name in final_df\n",
    "print(final_df['Function Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique DAG ID</th>\n",
       "      <th>Function Name</th>\n",
       "      <th>BERT Embedding</th>\n",
       "      <th>Max CPU Usage</th>\n",
       "      <th>Max Memory Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS-0eea2507-ed93-4f74-998f-f515e97d493a</td>\n",
       "      <td>AES1</td>\n",
       "      <td>[[-0.36717856, -0.3797353, 0.14636903, -0.0644...</td>\n",
       "      <td>1.344703</td>\n",
       "      <td>26.845184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS-0eea2507-ed93-4f74-998f-f515e97d493a</td>\n",
       "      <td>AES2</td>\n",
       "      <td>[[-0.3921602, -0.3868453, 0.109582104, -0.0756...</td>\n",
       "      <td>0.673485</td>\n",
       "      <td>21.921792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS-0eea2507-ed93-4f74-998f-f515e97d493a</td>\n",
       "      <td>AES3</td>\n",
       "      <td>[[-0.37413302, -0.37243375, 0.15295929, -0.056...</td>\n",
       "      <td>1.990102</td>\n",
       "      <td>32.206848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS-f06538f6-72db-4f30-b580-46eb0ff6c5f5</td>\n",
       "      <td>AES1</td>\n",
       "      <td>[[-0.3881844, -0.40802562, 0.124924146, -0.069...</td>\n",
       "      <td>0.657686</td>\n",
       "      <td>21.516288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS-f06538f6-72db-4f30-b580-46eb0ff6c5f5</td>\n",
       "      <td>AES2</td>\n",
       "      <td>[[-0.40800732, -0.415584, 0.123709925, -0.0662...</td>\n",
       "      <td>0.669833</td>\n",
       "      <td>21.827584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>AS-24aca0bf-9b4c-4ccc-b74b-4f813993027a</td>\n",
       "      <td>AES2</td>\n",
       "      <td>[[-0.4174613, -0.36204627, 0.15943323, -0.0755...</td>\n",
       "      <td>1.926353</td>\n",
       "      <td>29.966336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>AS-24aca0bf-9b4c-4ccc-b74b-4f813993027a</td>\n",
       "      <td>AES3</td>\n",
       "      <td>[[-0.396648, -0.36316627, 0.16283928, -0.08371...</td>\n",
       "      <td>2.346458</td>\n",
       "      <td>40.497152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>AS-c31d19ad-4769-47b3-afc7-5d101cbb50da</td>\n",
       "      <td>AES1</td>\n",
       "      <td>[[-0.3648185, -0.34650147, 0.1660411, -0.06320...</td>\n",
       "      <td>1.138118</td>\n",
       "      <td>24.358912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>AS-c31d19ad-4769-47b3-afc7-5d101cbb50da</td>\n",
       "      <td>AES2</td>\n",
       "      <td>[[-0.38517582, -0.36410168, 0.135017, -0.06388...</td>\n",
       "      <td>3.271595</td>\n",
       "      <td>24.162304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>AS-c31d19ad-4769-47b3-afc7-5d101cbb50da</td>\n",
       "      <td>AES3</td>\n",
       "      <td>[[-0.34607652, -0.3572317, 0.1760591, -0.05292...</td>\n",
       "      <td>2.406726</td>\n",
       "      <td>31.543296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Unique DAG ID Function Name  \\\n",
       "0     AS-0eea2507-ed93-4f74-998f-f515e97d493a          AES1   \n",
       "1     AS-0eea2507-ed93-4f74-998f-f515e97d493a          AES2   \n",
       "2     AS-0eea2507-ed93-4f74-998f-f515e97d493a          AES3   \n",
       "3     AS-f06538f6-72db-4f30-b580-46eb0ff6c5f5          AES1   \n",
       "4     AS-f06538f6-72db-4f30-b580-46eb0ff6c5f5          AES2   \n",
       "...                                       ...           ...   \n",
       "1495  AS-24aca0bf-9b4c-4ccc-b74b-4f813993027a          AES2   \n",
       "1496  AS-24aca0bf-9b4c-4ccc-b74b-4f813993027a          AES3   \n",
       "1497  AS-c31d19ad-4769-47b3-afc7-5d101cbb50da          AES1   \n",
       "1498  AS-c31d19ad-4769-47b3-afc7-5d101cbb50da          AES2   \n",
       "1499  AS-c31d19ad-4769-47b3-afc7-5d101cbb50da          AES3   \n",
       "\n",
       "                                         BERT Embedding  Max CPU Usage  \\\n",
       "0     [[-0.36717856, -0.3797353, 0.14636903, -0.0644...       1.344703   \n",
       "1     [[-0.3921602, -0.3868453, 0.109582104, -0.0756...       0.673485   \n",
       "2     [[-0.37413302, -0.37243375, 0.15295929, -0.056...       1.990102   \n",
       "3     [[-0.3881844, -0.40802562, 0.124924146, -0.069...       0.657686   \n",
       "4     [[-0.40800732, -0.415584, 0.123709925, -0.0662...       0.669833   \n",
       "...                                                 ...            ...   \n",
       "1495  [[-0.4174613, -0.36204627, 0.15943323, -0.0755...       1.926353   \n",
       "1496  [[-0.396648, -0.36316627, 0.16283928, -0.08371...       2.346458   \n",
       "1497  [[-0.3648185, -0.34650147, 0.1660411, -0.06320...       1.138118   \n",
       "1498  [[-0.38517582, -0.36410168, 0.135017, -0.06388...       3.271595   \n",
       "1499  [[-0.34607652, -0.3572317, 0.1760591, -0.05292...       2.406726   \n",
       "\n",
       "      Max Memory Usage  \n",
       "0            26.845184  \n",
       "1            21.921792  \n",
       "2            32.206848  \n",
       "3            21.516288  \n",
       "4            21.827584  \n",
       "...                ...  \n",
       "1495         29.966336  \n",
       "1496         40.497152  \n",
       "1497         24.358912  \n",
       "1498         24.162304  \n",
       "1499         31.543296  \n",
       "\n",
       "[1500 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiman/miniconda3/envs/nimbus/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./logs/500run2.csv')\n",
    "\n",
    "# Initialize DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Function to compute DistilBERT embeddings\n",
    "def get_distilbert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    # For DistilBERT, use `.last_hidden_state` to get the sequence of hidden-states at the output of the last layer\n",
    "    # Here we're taking the mean of these outputs to get a single vector representation of the text\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# List to store each row of the new dataset\n",
    "new_dataset_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    unique_dag_id = row['Unique DAG ID']\n",
    "    func_name = row['Function Name']\n",
    "    input_file_path = row['Input File']\n",
    "    \n",
    "    # Load the JSON content from the input file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Extract the specific part of the JSON relevant to the current function\n",
    "    if func_name in data['data']:\n",
    "        func_data = json.dumps(data['data'][func_name])\n",
    "        embedding = get_distilbert_embedding(func_data)\n",
    "        new_row = {\n",
    "            'Unique DAG ID': unique_dag_id,\n",
    "            'Function Name': func_name,\n",
    "            'BERT Embedding': embedding.tolist(),  # Convert numpy array to list for easier handling\n",
    "            'Max CPU Usage': row['Max CPU Usage'],\n",
    "            'Max Memory Usage': row['Max Memory Usage']\n",
    "        }\n",
    "        new_dataset_rows.append(new_row)\n",
    "\n",
    "# Convert the list of new rows into a DataFrame\n",
    "final_df = pd.DataFrame(new_dataset_rows)\n",
    "\n",
    "# Save the final dataset\n",
    "final_df.to_csv('./logs/functions_profiled_dataset_with_distilbert_embeddings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df['BERT Embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `df` is your DataFrame containing the embeddings, function names, and Max CPU Usage\n",
    "# Let's simulate loading the DataFrame here\n",
    "# df = pd.read_csv('functions_profiled_dataset_with_distilbert_embeddings.csv')\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = final_df.drop('Max CPU Usage', axis=1)\n",
    "y = final_df['Max CPU Usage']\n",
    "\n",
    "# One-hot encode the function name\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "function_names_encoded = encoder.fit_transform(X[['Function Name']])\n",
    "function_names_encoded_df = pd.DataFrame(function_names_encoded, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Assuming each embedding is stored as a list in the 'BERT Embedding' column\n",
    "# Convert the list of embeddings for each row into a separate DataFrame and concatenate them\n",
    "embeddings_list = list(X['BERT Embedding'])\n",
    "\n",
    "# Convert this list of lists into a 2D numpy array\n",
    "embeddings_array = np.array(embeddings_list)\n",
    "\n",
    "# Reshape the array to remove the unnecessary middle dimension\n",
    "embeddings_array = embeddings_array.reshape(embeddings_array.shape[0], embeddings_array.shape[2])\n",
    "\n",
    "# Create the DataFrame\n",
    "embeddings_df = pd.DataFrame(embeddings_array, columns=[f'embedding_{i}' for i in range(embeddings_array.shape[1])])\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the embeddings DataFrame\n",
    "X_encoded = pd.concat([function_names_encoded_df, embeddings_df], axis=1)\n",
    "X_encoded.columns = X_encoded.columns.astype(str)\n",
    "\n",
    "# concat features and target and write to csv\n",
    "write_df = pd.concat([X_encoded, y], axis=1)\n",
    "write_df.to_csv('./logs/parallelFunctionsBERT.csv', index=False)\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cpu_usage_error_rate(y_actual, y_predicted):\n",
    "        \"\"\"\n",
    "        Calculate the error rate for CPU usage predictions based on the criteria:\n",
    "        If the predicted value falls in the integer range of the actual value, then it is not an error.\n",
    "        \n",
    "        Args:\n",
    "            y_actual (array-like): The actual CPU usage values.\n",
    "            y_predicted (array-like): The predicted CPU usage values.\n",
    "            \n",
    "        Returns:\n",
    "            float: The error rate.\n",
    "            list: The list of errors.\n",
    "        \"\"\"\n",
    "        errors = 0\n",
    "        error_list = []\n",
    "        for actual, predicted in zip(y_actual, y_predicted):\n",
    "            actualError = abs(actual - predicted)/actual\n",
    "            error_list.append(actualError)\n",
    "            # Check if predicted falls outside the integer range of actual\n",
    "            if not (int(actual) <= predicted < int(actual) + 1):\n",
    "                errors += 1\n",
    "        \n",
    "        error_rate = errors / len(y_actual)\n",
    "        return error_rate,error_list\n",
    "\n",
    "def calculate_memory_usage_error_rate(y_actual, y_predicted):\n",
    "        \"\"\"\n",
    "        Calculate the error rate for memory usage predictions based on the criteria:\n",
    "        A prediction is considered an error if it falls outside the +5 and -5 range of the actual value.\n",
    "        \n",
    "        Args:\n",
    "            y_actual (array-like): The actual memory usage values.\n",
    "            y_predicted (array-like): The predicted memory usage values.\n",
    "            \n",
    "        Returns:\n",
    "            float: The error rate.\n",
    "            list: The list of errors.\n",
    "        \"\"\"\n",
    "        errors = 0\n",
    "        error_list = []\n",
    "        for actual, predicted in zip(y_actual, y_predicted):\n",
    "            actualError = abs(actual - predicted)/actual\n",
    "            error_list.append(actualError)\n",
    "            if not (actual - 5 <= predicted <= actual + 5):\n",
    "                errors += 1\n",
    "        \n",
    "        error_rate = errors / len(y_actual)\n",
    "        return error_rate,error_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Error Rate: 0.3377777777777778\n"
     ]
    }
   ],
   "source": [
    "errRate, errList = calculate_cpu_usage_error_rate(y_test, y_pred)\n",
    "print(f'CPU Error Rate: {errRate}')\n",
    "# errRate, errList = calculate_memory_usage_error_rate(y_test, y_pred)\n",
    "# print(f'Memory Error Rate: {errRate}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nimbus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
